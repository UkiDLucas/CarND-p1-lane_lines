{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "\n",
    "by Uki D. Lucas\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Table of Contents\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3 and Jupyter have support for greek math symbols.\n",
    "\n",
    "- alpha : $\\alpha$\n",
    "- beta : $\\beta$\n",
    "- rho : $\\rho$\n",
    "- theta : $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define RGB colors used in the code\n",
    "RED = color=[255, 0, 0]\n",
    "GREEN = color=[0, 255, 0]\n",
    "BLUE = color=[0, 0, 255]\n",
    "WHITE = color=[255, 255, 255]\n",
    "GRAY = color=[192, 192, 192]\n",
    "VIOLET = color=[153, 51, 255]\n",
    "ORANGE = color=[255, 128, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading in an image\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg') # original homework image\n",
    "#image = mpimg.imread('test_images/bouquet_cyn_curve.jpg') # add on mountain curve\n",
    "#image = mpimg.imread('test_images/solidWhiteCurve.jpg')\n",
    "#image = mpimg.imread('test_images/Challenge001.jpg') # intense shadows\n",
    "#image = mpimg.imread('test_images/Challenge002.jpg') # intense shadows\n",
    "\n",
    "\n",
    "# printing out some stats and plotting\n",
    "# print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grayscale\n",
    "Since we are detecting road lines we want to show contrast and we do not care about color at this time (white line vs yellow line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "# TEST the function\n",
    "image_gray = grayscale(image)\n",
    "plt.imshow(image_gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Blur\n",
    "\n",
    "I have tested kernel_size in different values, but generally 5 is good as you do want to have some blur in the image to hide the road imperfections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gaussian_blur(image, kernel_size=5): # 5 is good for homework\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# Test the function\n",
    "image_gaussian = gaussian_blur(image_gray, kernel_size=5)\n",
    "plt.imshow(image_gaussian, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edges\n",
    "\n",
    "This is one of the places where it is easy t overfit for particular conditions.\n",
    "Generally, I want to see as many line edges as possible but not to see irregular shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def canny(image, low_threshold=50, high_threshold=250): # homework low_threshold=20, high_threshold=130\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "# Test the function\n",
    "image_canny = canny(image_gaussian)\n",
    "plt.imshow(image_canny, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Test the function\n",
    "image_canny = canny(image_gaussian, low_threshold=50, high_threshold=250)\n",
    "plt.imshow(image_canny, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking (using polygon vertices)\n",
    "\n",
    "I have designed a polygon that has fit multiple scenarios (different roads). \n",
    "***In the future***, I would like to adjust the shape of the polygon depending on which way the *** average slope (center line)*** is leaning to adjust for turns. I admit that the polygon is biased towards straigh road and gentle curves, for Pikes Peak the polygon has to adjust to the sides.\n",
    "\n",
    "- on the top do not be afraid to cut off\n",
    "- in the middle you have to leave some room for turns\n",
    "- on the bottom start high because of the dashboard\n",
    "- we are NOT following a center line in this code, so cut it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mask_vertices(image, horizon_offset_percent=-10):\n",
    "    \"\"\"\n",
    "    I decided to go with following polygon \n",
    "    after fitting several mountain curve roads.\n",
    "    It is important not to use pixels as each video may be different.\n",
    "    horizon_offset = -10 % percent negative mean UNDER the (mid-screen) horizon\n",
    "    I would like to go as high as possible,\n",
    "    but in reality only about bottom 40% of the screen is relevant\n",
    "    \"\"\"\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    \n",
    "    horizon_offset = height*horizon_offset_percent/100\n",
    "\n",
    "    # on the top do not be afraid to cut off\n",
    "    top_left = (width*0.45, height/2 - horizon_offset)\n",
    "    top_right = (width-width*0.45, height/2 - horizon_offset)\n",
    "    \n",
    "    # in the mid you have to leve some room for turns\n",
    "    mid_left = (width*0.15, height*0.8) \n",
    "    mid_right = (width-width*0.15, height*0.8)\n",
    "    \n",
    "    # on the bottom start high because of the dashboard\n",
    "    bottom_center_left = (width*0.27, height*0.95) \n",
    "    bottom_center_right = (width-width*0.27, height*0.95) \n",
    "    \n",
    "    # we are NOT following a center line in this code, so cut it out\n",
    "    bottom_center = (width/2, height*0.65) \n",
    "\n",
    "\n",
    "    # add points clockwise\n",
    "    vertices = np.array([[ \n",
    "                top_left, top_right, \n",
    "                mid_right, \n",
    "                bottom_center_right, bottom_center, bottom_center_left,\n",
    "                mid_left \n",
    "                 ]], dtype=np.int32)\n",
    "    return vertices\n",
    "\n",
    "\n",
    "# Test the region_of_interest function\n",
    "image_mask = region_of_interest(image, mask_vertices(image))\n",
    "plt.imshow(image_mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "image_mask = region_of_interest(image, mask_vertices(image, horizon_offset_percent=-8))\n",
    "plt.imshow(image_mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_mask = region_of_interest(image_canny, mask_vertices(image))\n",
    "plt.imshow(image_mask, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order of coordinates in the line\n",
    "\n",
    "For sanity sake when calculating things, I adjusted all lines so:\n",
    "- x1, y1 coordinated were always above\n",
    "- x2, y2 coordinated were always below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arrangeLineCoordinates(line):\n",
    "    \"\"\"\n",
    "    This method enforces that given line,\n",
    "    has x1, y1 on TOP\n",
    "    and x2, y2 on the BOTTOM of the image.\n",
    "    \n",
    "    It is user responsibility to test\n",
    "    if line is a valid object.\n",
    "    I have no way to know what to return otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if y1 > y2:\n",
    "                # print(\"WARNING y1 > y2 swapping the order\")\n",
    "                temp_x2 = x1\n",
    "                temp_y2 = y1\n",
    "                temp_x1 = x2\n",
    "                temp_y1 = y2\n",
    "\n",
    "                x1 = temp_x1\n",
    "                x2 = temp_x2\n",
    "                y1 = temp_y1\n",
    "                y2 = temp_y2   \n",
    "                line = np.array([[x1, y1, x2, y2]], np.int32)\n",
    "    except ValueError:\n",
    "        #print(\"Provided line has unexpected values\", line)\n",
    "        line = np.array([[0, 0, 0, 0]], np.int32)\n",
    "    except TypeError:\n",
    "        # Use this as visual clue that line is not correct\n",
    "        #print(\"Provided line has unexpected type\", type(line))\n",
    "        line = np.array([[0, 0, 0, 0]], np.int32)\n",
    "                \n",
    "    return line\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw lines\n",
    "\n",
    "This method is pretty much close to original, except for error handling, e.g. sometimes no lines are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color=WHITE, thickness=1):\n",
    "    \"\"\"   \n",
    "    Lines are drown over the image, i.e. mutates the image.\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    if lines is not None: # no point processing is no lines were found\n",
    "        for line in lines:\n",
    "            try:\n",
    "                if line is not None: # TypeError: 'NoneType' object is not iterable\n",
    "                    line = arrangeLineCoordinates(line)\n",
    "                    for x1,y1,x2,y2 in line:\n",
    "                        cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "            except ValueError:\n",
    "                #print(\"Oops!  draw_lines\", line)\n",
    "                cv2.line(image, (0, 0), (0, 0), color, thickness)\n",
    "            except TypeError:\n",
    "                #print(\"Oops!  draw_lines\", line)\n",
    "                cv2.line(image, (0, 0), (0, 0), color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean (average)\n",
    "\n",
    "I have made use of averageing techniques in couple of versions of this project for slopes and y_intercepts and I plan in the future to use that technique, the effect is smoothness. However, using averages is dangerous and gives you a \"fake\" lines, so there is definitely a tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    if 0 == max(len(numbers), 1):\n",
    "        return float(\"NaN\")\n",
    "    return float(sum(numbers)) / max(len(numbers), 1) #TODO check division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Slope\n",
    "\n",
    "I have used a function to calculate slope for each line to determine if it belongs to LEFT or RIGHT side, and to throw away these that are clearly wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_slope(x1, y1, x2, y2):        \n",
    "    rise = y2 - y1\n",
    "    \n",
    "    run = x2 - x1\n",
    "    try:\n",
    "        slope = rise/run\n",
    "        return slope\n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivisionError: calc_slope the slope cannot be calculated for a VERTICAL LINE.\")\n",
    "    \n",
    "\n",
    "# TEST\n",
    "print(calc_slope(-1, 2, 1, 3))\n",
    "print(calc_slope(2, 2, 1, 3))\n",
    "print(calc_slope(1, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rounding floats to integers\n",
    "\n",
    "When calculating slope we end up with floats, when calculating coordinates from slopes we need to convers results back to integers. This method is not generic as it handles infinity in special way (as a large number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def round_int(x):\n",
    "    if x == float(\"inf\") or x == float(\"-inf\"):\n",
    "        # return float('nan') # or x or return whatever makes sense\n",
    "        return 1000\n",
    "    return int(round(x))\n",
    "\n",
    "# TEST\n",
    "print(round_int(174.919753086))\n",
    "print(round_int(0))\n",
    "print(round_int(float(\"inf\")))\n",
    "print(round_int(float(\"-inf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_y_intercept(slope, x, y):\n",
    "    return y - (x * slope)\n",
    "\n",
    "#test\n",
    "slope = -(2/3)\n",
    "x = -3\n",
    "y = 3\n",
    "print(calc_y_intercept(slope, x, y))\n",
    "\n",
    "\n",
    "slope = -(2/3)\n",
    "x = 3\n",
    "y = -1\n",
    "print(calc_y_intercept(slope, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y Intercept\n",
    "\n",
    "Similarly to slope, the calculation of y-intercept is essential to solve for coordinates.\n",
    "I needed to handle infinity and Nan as well as division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_x(slope, y, y_intercept):\n",
    "    \n",
    "    if math.isnan(slope): # vertical line cannot have a slope\n",
    "        return float('nan')\n",
    "    if slope == float('Inf') or slope == -float('Inf'):\n",
    "        return float('nan')\n",
    "    if y_intercept == float('Inf') or y_intercept == -float('Inf'):\n",
    "        return float('nan')\n",
    "    \n",
    "    result = 0 # temp\n",
    "    try:\n",
    "        if slope == 0: # flat line\n",
    "            slope = 0.01 # avoid division by zero, result will be a large number, almost flat line\n",
    "        x = (y - y_intercept)/slope\n",
    "        result = round_int(x)\n",
    "    except ValueError:\n",
    "        print(\"ValueError: calc_x That was no valid number.  slope\", slope, \"y\", y, \"y_intercept\", y_intercept)\n",
    "    return   result\n",
    "\n",
    "# TEST\n",
    "y = -1\n",
    "y_intercept = 1\n",
    "\n",
    "slope = -(2/3)\n",
    "# 3 expected\n",
    "print(\"x =\", calc_x(slope, y, y_intercept))\n",
    "\n",
    "slope = 1\n",
    "print(\"x =\", calc_x(slope, y, y_intercept))\n",
    "\n",
    "slope = 0\n",
    "print(\"x =\", calc_x(slope, y, y_intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine LEFT and RIGHT side\n",
    "\n",
    "This method is essential as is divides lines to sides of the road and eliminates the irrelevant lines.\n",
    "Please take in consideration that I consider the slope value as well as where the line intersects the bottom of the image. If the line is way off to the side I cansider it irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def side(image, line):\n",
    "    \"\"\"\n",
    "    This function determines if line\n",
    "    should be procesed as \"left\", \"right\"\n",
    "    or rejected entirely as irrelevant.\n",
    "\n",
    "    side: LEFT, slope -0.923076923077\n",
    "    side: RIGHT, slope 0.65\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    width = image.shape[1] # right of the image frame\n",
    "    height = image.shape[0] # bottom of the image frame\n",
    "\n",
    "    for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "        slope = calc_slope(x1,y1,x2,y2)\n",
    "        intercept = calc_y_intercept(slope, x1, y1)\n",
    "        # I am interested where is x (left, or right)\n",
    "        # if you extend the line to the bottom of the image\n",
    "        y2 = height\n",
    "        x2 = calc_x(slope, y2 , intercept) \n",
    "\n",
    "        if (0 < x2 < width/2 - width*0.1) and (-0.95 < slope < -0.20) : # LEFT negative\n",
    "            return \"left\"\n",
    "        elif  (width/2 + width*0.1 < x2 < width ) and (0.8 > slope > 0.25): # RIGHT positive\n",
    "            # print(\"side: RIGHT, slope\", slope)\n",
    "            return \"right\"\n",
    "        else:\n",
    "            # print(\"irrelevant, slope\", slope, \"x2\", x2)\n",
    "            return \"irrelevant\" # the line extends off screen, to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Hugh lines\n",
    "\n",
    "This part of the code was the BULK of work (together with the sides). \n",
    "I decided that a plausible technique would be to:\n",
    "\n",
    "- divide Hough lines into LEFT, RIGHT and IRRELEVANT based on the slope and intersection of the bottom\n",
    "- find the longest detected line on each side\n",
    "- extend it to the bottom\n",
    "- extend it to the top-most detected point on this side\n",
    "- draw different types of lines in different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hough_lines(image, rho=2, theta=np.pi/180, threshold=20, min_line_len=30, max_line_gap=20):\n",
    "    \"\"\"\n",
    "    - rho ρ is the distance from the origin\n",
    "    - theta θ is the angle\n",
    "    - min_line_len minimum length of a line that will be created\n",
    "    - max_line_gap maximum distance between segments that will be connected to a single line\n",
    "    - threshold increasing(~ 50-60) will rule out the spurious lines.\n",
    "    defines the minimum number of intersections in a given grid cell that are required to choose a line.)\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(image, rho, theta, threshold, np.array([]), \n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    if lines is None: # no point processing if no lines were found\n",
    "        return image\n",
    "    \n",
    "    width = image.shape[1] # right of the image frame\n",
    "    height = image.shape[0] # bottom of the image frame\n",
    "\n",
    "    left_longest_line = 0\n",
    "    right_longest_line = 0\n",
    "\n",
    "    relevant_hough_lines_left = [] \n",
    "    relevant_hough_lines_right = [] \n",
    "    rejected_hough_lines = []\n",
    "    longest_lines_left = []\n",
    "    longest_lines_right = []\n",
    "\n",
    "    longest_right = 0\n",
    "    longest_left = 0\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "\n",
    "            # get vertical HEIGHT of this line \n",
    "            y_difference = abs(y2 - y1)\n",
    "\n",
    "            # Categorize the lines to LEFT | RIGHT \n",
    "            side_detected = side(image, line)\n",
    "            \n",
    "            if \"left\" == side_detected:\n",
    "                relevant_hough_lines_left.append(line)\n",
    "                if y_difference > longest_left:\n",
    "                    left_longest_line = line\n",
    "                    longest_left = y_difference\n",
    "                    \n",
    "            elif  \"right\" == side_detected:\n",
    "                relevant_hough_lines_right.append(line)\n",
    "                if y_difference > longest_right:\n",
    "                    right_longest_line = line\n",
    "                    longest_right = y_difference\n",
    "\n",
    "            else:\n",
    "                rejected_hough_lines.append(line) # WHITE\n",
    "\n",
    "    longest_lines_left.append(left_longest_line)  # ORANGE \n",
    "    longest_lines_right.append(right_longest_line) # ORANGE \n",
    "    \n",
    "    # draw a blank black image\n",
    "    image_lines = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    # draw color-coded HOUGH lines\n",
    "    # Most of the time I do not want to draw all of the WHITE lines   \n",
    "    #draw_lines(image_lines, lines, color=WHITE, thickness=2)\n",
    "    draw_lines(image_lines, relevant_hough_lines_left, color=BLUE, thickness=2)\n",
    "    draw_lines(image_lines, relevant_hough_lines_right, color=GREEN, thickness=2)\n",
    "    draw_lines(image_lines, longest_lines_left, color=ORANGE, thickness=2)\n",
    "    draw_lines(image_lines, longest_lines_right, color=ORANGE, thickness=2)\n",
    "    \n",
    "    \n",
    "    # if no higher point is found I will draw up to this\n",
    "    highest_y = round_int(height*0.8) \n",
    "\n",
    "\n",
    "    \n",
    "    # LEFT\n",
    "    slopes_left = []\n",
    "    left_highest_y = highest_y\n",
    "    for line in relevant_hough_lines_left:\n",
    "        for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "            slope = calc_slope(x1,y1,x2,y2)\n",
    "            slopes_left.append(slope)\n",
    "            if y1 < left_highest_y: # find highest relevant y LEFT\n",
    "                left_highest_y = y1\n",
    "                \n",
    "                    \n",
    "    # RIGHT\n",
    "    slopes_right = []\n",
    "    right_highest_y = highest_y \n",
    "    for line in relevant_hough_lines_right:\n",
    "        for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "            slope = calc_slope(x1,y1,x2,y2)\n",
    "            slopes_right.append(slope)\n",
    "            if y1 < right_highest_y: # find highest relevant y RIGHT\n",
    "                right_highest_y = y1\n",
    "    \n",
    "    # Draw EXTENDED LONGEST lines in BLUE\n",
    "    for line in longest_lines_left:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "                slope = calc_slope(x1,y1,x2,y2)\n",
    "                intercept = calc_y_intercept(slope, x1, y1)\n",
    "                # I am interested in the UPPER most relevant point y\n",
    "                y1 = left_highest_y # highest point to draw LEFT\n",
    "                x1 = calc_x(slope, y1, intercept)\n",
    "\n",
    "                # I am interested where is x (left, or right)\n",
    "                # if you extend the line to the bottom of the image\n",
    "                y2 = height\n",
    "                x2 = calc_x(slope, y2, intercept)\n",
    "                # Draw PREDICTED BLUE line\n",
    "                cv2.line(image_lines, (x1, y1), (x2, y2), color=RED, thickness=8)\n",
    "        except ValueError:\n",
    "            # print(\"ValueError: provided line has bad values\", line)\n",
    "            cv2.line(image_lines, (0, 0), (0, 0), color=WHITE, thickness=1)\n",
    "        except TypeError:\n",
    "            # Giving myself a visual clue \n",
    "            # print(\"TypeError: the provided line is of a wrong type\", type(line))\n",
    "            cv2.line(image_lines, (0, 0), (0, 0), color=WHITE, thickness=1)\n",
    "            \n",
    "    # Draw EXTENDED LONGEST lines in BLUE\n",
    "    for line in longest_lines_right:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in arrangeLineCoordinates(line):\n",
    "                slope = calc_slope(x1,y1,x2,y2)\n",
    "                intercept = calc_y_intercept(slope, x1, y1)\n",
    "                # I am interested in the UPPER most relevant point y\n",
    "                y1 = right_highest_y # highest point to draw LEFT\n",
    "                x1 = calc_x(slope, y1, intercept)\n",
    "\n",
    "                # I am interested where is x (left, or right)\n",
    "                # if you extend the line to the bottom of the image\n",
    "                y2 = height\n",
    "                x2 = calc_x(slope, y2, intercept)\n",
    "                # Draw PREDICTED BLUE line\n",
    "                cv2.line(image_lines, (x1, y1), (x2, y2), color=RED, thickness=8)\n",
    "        except ValueError:\n",
    "            # print(\"ValueError: provided line has bad values\", line)\n",
    "            cv2.line(image_lines, (0, 0), (0, 0), color=WHITE, thickness=1)\n",
    "        except TypeError:\n",
    "            # Giving myself a visual clue \n",
    "            # print(\"TypeError: the provided line is of a wrong type\", type(line))\n",
    "            cv2.line(image_lines, (0, 0), (0, 0), color=WHITE, thickness=1)\n",
    "    \n",
    "    \n",
    "    draw_lines(image_lines, rejected_hough_lines, color=VIOLET, thickness=1)\n",
    "    \n",
    "    return image_lines\n",
    "\n",
    "\n",
    "# TEST  \n",
    "image_hough_lines = hough_lines(image_mask)\n",
    "plt.imshow(image_hough_lines)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image_hough_lines = hough_lines(image_mask, rho=2, theta=np.pi/180, threshold=25, min_line_len=25, max_line_gap=20)\n",
    "plt.imshow(image_hough_lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"all Hough lines - WHITE\")\n",
    "print(\"relevant Hough lines right - GREEN\")\n",
    "print(\"relevant Hough lines left - RED\")\n",
    "print(\"rejected Hough lines - GRAY\")\n",
    "print(\"longest lines - ORANGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay of multiple images\n",
    "\n",
    "In the first try I had separate masks for left and right, this made things very simple, but did not work very well in sharp turns.\n",
    "I have tried with several values, but overall effect was good enough with the values below (close to original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_img(image_mask, image_original, α=0.9, β=1., λ=0.1):\n",
    "    \"\"\"\n",
    "    The result image is computed as follows:\n",
    "    image_original * α + image_mask * β + λ\n",
    "    The image_original and image_mask must be the same shape.\n",
    "    \n",
    "    Beta β= affects the background\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(image_original, α, image_mask, β, λ)\n",
    "\n",
    "# Test function\n",
    "image_weighted = weighted_img(image, image_hough_lines, α=0.9, β=0.9, λ=0.5)\n",
    "plt.imshow(image_weighted, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "image_weighted = weighted_img(image, image_hough_lines, α=0.9, β=1., λ=0.1)\n",
    "plt.imshow(image_weighted, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The image pipeline\n",
    "\n",
    "After figuring out all my default parameters (described above), combining the pipline could be made clean by skipping all the unnecessary parameters.\n",
    "\n",
    "Please note that the TEST pipeline is above with each function processing the test image, and the PRODUCTION pipeline is below using default parameters. Each step of the pipline takes an image that was modified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    # NOTE: The output you return should be a color image (3 channel) \n",
    "    # for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    image_copy = np.copy(image) \n",
    "    image_gray = grayscale(image_copy)\n",
    "    image_gaussian = gaussian_blur(image_gray)\n",
    "    image_canny = canny(image_gaussian)\n",
    "    image_mask = region_of_interest(image_canny, mask_vertices(image_canny))\n",
    "    image_hough_lines = hough_lines(image_mask)\n",
    "    image_weighted = weighted_img(image, image_hough_lines)\n",
    "\n",
    "    return image_weighted\n",
    "\n",
    "image_result = process_image(image)\n",
    "plt.imshow(image_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images\n",
    "\n",
    "Now you should build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_list = os.listdir(\"test_images/\")\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in image_list:\n",
    "    # print(\"fetching image\", name)\n",
    "    if \".jpg\" in name: # name sure we are not trying to read Mac .DS_Store\n",
    "        print(\"processing image\", name)\n",
    "        image = mpimg.imread('test_images/' + name)\n",
    "        image_result = process_image(image)\n",
    "        plt.imshow(image_result)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run your solution on all test_images and make copies into the test_images directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# ERROR\n",
    "# NeedDownloadError                         Traceback (most recent call last)\n",
    "# /Users/ukilucas/anaconda3/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py in get_exe()\n",
    "#      81             exe = get_remote_file('ffmpeg/' + FNAME_PER_PLATFORM[plat],\n",
    "\n",
    "# TO FIX THE ERROR\n",
    "# >>> import imageio\n",
    "# >>> imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "new_clip = clip.fl_image( process_image )\n",
    "%time new_clip.write_videofile(white_output, audio=False)\n",
    "# before optimzation 221/222 [00:07<00:00, 31.22it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "i=0\n",
    "for frame in clip.iter_frames():\n",
    "    print(i)\n",
    "    image_result = process_image(frame)\n",
    "    plt.imshow(image_result, cmap='gray')\n",
    "    plt.show()\n",
    "    %time  i+=1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, if you were successful you probably have the Hough line segments drawn onto the road, but what about identifying the full extent of the lane and marking it clearly as in the example video (P1_example.mp4)?  Think about defining a line to run the full length of the visible lane based on the line segments you identified with the Hough Transform.  Modify your draw_lines function accordingly and try re-running your pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "# before optimization 681/682 [00:23<00:00, 29.58it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "Congratulations on finding the lane lines!  As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail?\n",
    "\n",
    "Please add your thoughts below,  and if you're up for making your pipeline more robust, be sure to scroll down and check out the optional challenge video below!\n",
    "\n",
    "\n",
    "# MY COMMENTS (future plans)\n",
    "\n",
    "1) I would like to compute the the HORIZON point as intersection of the 2 slopes LEFT and RIGHT and ignore points above it dynamically\n",
    "2) I would like to adjust the shape of the mask polygon depending on the turn\n",
    "3) Depending on the final need of this exercise I might add some averaging to SMOOTH the prediction lines\n",
    "4) I would like to consider only the lines that \"stack on top of each other\" which means that y coordinates form a sequence (one line above the other) and slopes are very similar and y-intersects are very similar\n",
    "5) I would like to use a CURVE (quadratic function) instead of straigh line (linear funcion) because road is almost never straight (sorry Nebraska!)\n",
    "6) I have run this code agaist the curvy road up the Pikes Peak and would love to continue working on that until perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you're satisfied with your video outputs it's time to submit!  Submit this ipython notebook for review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "# before optimization 251/251 [00:16<00:00, 14.86it/s]\n",
    "# 251/251 [00:13<00:00, 19.28it/s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments to challenge\n",
    "\n",
    "Please note that I extend the lines ONLY to the TOP-MOST point detected on each side and not to some artificial height (e.g. horizon, screen height/2), which would be much easier. \n",
    "\n",
    "This was a concious decision as the SHORTER line indicates that computer is NOT SURE and the car should:\n",
    "- slow down\n",
    "- favor alternative means to judge distance from objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
